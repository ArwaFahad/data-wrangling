{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Data wrangling of this project we have been go through 3 main steps of this prosses:<br>\n",
    "<br>***1)\tDATA GATHERING<br>***\n",
    "        At this step we gather the data that we will work in with a 3 different ways:<br>\n",
    "        First, we download the “twitter archive file” that contain all the tweets that we will analysis manually, by download it from the given link then upload it into the Jupyter notebook.<br>\n",
    "Second,  we download the “image prediction file” that contain all the images of the tweets \n",
    "Programmatically, by using python Requests library.<br>\n",
    "Third,  we download the “json tweets file” that contain all the information of the tweets \n",
    "Using Tweepy library to access twitter API – BUT actually we didn’t use this way we only wrote the code of it since twitter reject our account to be a developer – instead we download the text file then use JSON to read the data line by line then extract the one we need and store it in file.<br>\n",
    "<br>***2)\tDATA ASSESSING<br>***\n",
    "After we have gather all the needed data, we start assess each file visually and Programmatically, then we document down all the observed quality and tidiness issues.<br>\n",
    "<br>\n",
    "**Quality Issues:<br>**\n",
    "•\tThere are some unclear columns names.<br>\n",
    "•\tThere are some un appropriate data types.<br>\n",
    "•\tThere are a lot of null values in some columns.<br>\n",
    "•\tThere are some invalid names in (name) column.<br>\n",
    "•\ttimestamp , retweeted_status_timestamp columns should be datetime not object.<br>\n",
    "•\tWe only want original ratings (no retweets) that have images.<br>\n",
    "•\tThere are only 2075 records instead of 2356 so there are some missing records.<br>\n",
    "•\ttweet_id type is better to change to string, since sometime these IDs may exceed limit of int.<br>\n",
    "\n",
    "**Tidness Issues:<br>**\n",
    "•\tall tables should be merge in one.<br>\n",
    "•\tthe 4 stages of dogs should be in only one column instead of four.<br>\n",
    "\n",
    "<br>***3)\tDATA CLEANING<br>***\n",
    "Now in this step since we have all the data and we know the issues within itm we start the process of cleaning by fixing the issues. Since this process have a three step:<br>\n",
    "Define , code and test, we wrote a small comment before each code to help to understand the purpose of the code. And after each  cleaning we display the data Programmatically to make sure that the changes that we have made is worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
